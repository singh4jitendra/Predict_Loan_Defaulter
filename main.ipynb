{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'.\\\\data\\\\companies.txt' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-226-20b618a85a70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m#Read data from companies.txt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mcomp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\".\\data\\companies.txt\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'ISO-8859-1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m#Read data from rounds2.csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'.\\\\data\\\\companies.txt' does not exist"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "\n",
    "# Method to replace '0' with 'na'/'Na' appropriately\n",
    "def replace_0_with_na(s):\n",
    "    s = str(s)\n",
    "    if(s.startswith(\"0\")):\n",
    "        s =s.replace(\"0\",\"Na\")\n",
    "    elif(s.count(\"0\") >0 and s.index(\"0\") >0):\n",
    "        s= s.replace(\"0\",\"na\")\n",
    "    return s\n",
    "\n",
    "\n",
    "#Method to convert value to Billion\n",
    "def billions(x, pos):\n",
    "    return '$%1.1fB' % (x*1e-9)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Read data from companies.txt\n",
    "comp = pd.read_csv(r\".\\data\\companies.txt\" , encoding ='ISO-8859-1',delimiter = \"\\t\")\n",
    "\n",
    "#Read data from rounds2.csv\n",
    "rounds2 = pd.read_csv(r\".\\data\\rounds2.csv\" , encoding ='ISO-8859-1')\n",
    "\n",
    "#Making all values of 'company_permalink' column to lowercase to count unique values\n",
    "uniq_comp_in_rounds2 = rounds2['company_permalink'].map(lambda x: x.split(\"/\")[2].lower())\n",
    "\n",
    "\n",
    "\n",
    "#Q.1 How many unique companies are present in companies?\n",
    "print(\"\\nunique companies are present in companies : %d\" %(comp.permalink.nunique()))\n",
    "\n",
    "#Q.2 How many unique companies are present in rounds2?\n",
    "print(\"\\nunique companies are present in rounds2: %d\" %(uniq_comp_in_rounds2.nunique()))\n",
    "\n",
    "#Q.3 In the companies data frame, which column can be used as the unique key for each company? Write the name of the column.\n",
    "print(\"Unique Column : permalink\")\n",
    "\n",
    "\n",
    "#Q.4 Are there any companies in the rounds2 file which are not present in companies? Answer yes or no: Y/N\n",
    "comp_in_rounds2_and_not_in_comp = (uniq_comp_in_rounds2.nunique() -comp.permalink.nunique())\n",
    "if(comp_in_rounds2_and_not_in_comp > 0):\n",
    "    print(\"Yes, we have 2 companies in the rounds2, which is not in companies.txt\")\n",
    "\n",
    "\n",
    "#Q.5 Merge the two data frames so that all variables (columns).\n",
    "\n",
    "#Renaming company_permalink to permalink for ease of merge\n",
    "rounds2.rename(columns={'company_permalink': 'permalink'}, inplace=True)\n",
    "comp['permalink'] = comp['permalink'].str.lower()\n",
    "rounds2['permalink'] = rounds2['permalink'].str.lower()\n",
    "master_frame = pd.merge(comp, rounds2,  on='permalink', how=\"outer\")\n",
    "print(\"No. of observaitons : %s \" %(master_frame.shape[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Table 2.1\n",
    "\"\"\" \n",
    "\n",
    "\n",
    "#Filtering with funding_round_type column\n",
    "df_funding = master_frame[\"funding_round_type\"]\n",
    "\n",
    "total_venture =  master_frame[df_funding == \"venture\"].shape[0]\n",
    "total_angel =  master_frame[df_funding == \"angel\"].shape[0]\n",
    "total_seed =  master_frame[df_funding == \"seed\"].shape[0]\n",
    "total_private_equity =  master_frame[df_funding == \"private_equity\"].shape[0]\n",
    "\n",
    "\n",
    "master_frame_with_total_raised_amount_sum_for_all_type_of_funding = master_frame.groupby('funding_round_type').raised_amount_usd.mean()\n",
    "print(\"Average_ventur         : %.2f\" %(master_frame_with_total_raised_amount_sum_for_all_type_of_funding[\"venture\"]))\n",
    "print(\"Average_angel          : %.2f\" %(master_frame_with_total_raised_amount_sum_for_all_type_of_funding[\"angel\"]))\n",
    "print(\"Average_seed           : %.2f\" %(master_frame_with_total_raised_amount_sum_for_all_type_of_funding[\"seed\"]))\n",
    "print(\"Average_private_equity : %.2f\" %(master_frame_with_total_raised_amount_sum_for_all_type_of_funding[\"private_equity\"]))\n",
    "\n",
    "\n",
    "\n",
    "#Considering that Spark Funds wants to invest between 5 to 15 million USD per investment round, \n",
    "#which investment type is the most suitable for it?\n",
    "\n",
    "USD_5M=master_frame[\"raised_amount_usd\"] >= 500000\n",
    "USD_15M=master_frame[\"raised_amount_usd\"] <= 1500000\n",
    "df_5M_15M_USD = master_frame[(USD_5M) & (USD_15M)]\n",
    "\n",
    "most_suitable_investment_type =  df_5M_15M_USD.groupby('funding_round_type').raised_amount_usd.sum().idxmax()\n",
    "print(\"Most suitable investment type : %s\" %(most_suitable_investment_type))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "Table 3.1\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "venture_master_frame = master_frame[df_funding == \"venture\"]\n",
    "\n",
    "venture_master_frame_with_total_raised_amount_sum = venture_master_frame.groupby('country_code').raised_amount_usd.sum()\n",
    "top_9_countries = venture_master_frame_with_total_raised_amount_sum.sort_values(ascending=False).head(9)\n",
    "\n",
    "print(top_9_countries[['USA', 'GBR', 'IND']]) \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Table 5.1\n",
    "\"\"\"\n",
    "\n",
    "########### Extract the primary sector of each category list from the category_list column and putting in master frame\n",
    " \n",
    "mapping = pd.read_csv(r\".\\data\\mapping.csv\" , encoding ='ISO-8859-1')\n",
    "df_primary_sector = master_frame['category_list'].apply(lambda x: str(x).split('|')[0])\n",
    "master_frame[\"primary_sector\"] = pd.DataFrame(df_primary_sector.values)\n",
    "\n",
    "\n",
    "############# Use the mapping file 'mapping.csv' to map each primary sector to one of the eight main sector \n",
    "\n",
    "#reversing one-hot encoding\n",
    "df_mapping_with_main_sector = mapping\n",
    "df_mapping_with_main_sector[\"main_sector\"] = pd.get_dummies(mapping).idxmax(1)\n",
    "df_mapping_with_main_sector.drop(mapping.columns[[1,2,3,4,5,6,7,8,9]], axis = 1, inplace = True) \n",
    "\n",
    "\n",
    "###############  Removing '0' from category_list e.g. A0lytics=>Analytics ###########\n",
    "master_frame[\"category_list\"] = master_frame[\"category_list\"].apply(replace_0_with_na)\n",
    "df_mapping_with_main_sector[\"category_list\"] = df_mapping_with_main_sector[\"category_list\"].apply(replace_0_with_na)\n",
    "\n",
    "\n",
    "###############  Mapping main_sector in master_Frame from mapping frame  ###########\n",
    "master_frame['main_sector'] = master_frame['primary_sector'].map(df_mapping_with_main_sector.set_index('category_list')['main_sector'])\n",
    "\n",
    "\n",
    "\n",
    "################## Table 5.1 ###################\n",
    "\n",
    "venture_master_frame_with_main_sector = master_frame[df_funding == \"venture\"]\n",
    "venture_master_frame_with_main_sector_with_5M_and15M_inestment = venture_master_frame_with_main_sector[(USD_5M2) & (USD_15M2)]\n",
    "df_country = venture_master_frame_with_main_sector_with_5M_and15M_inestment[\"country_code\"]\n",
    "D1 =  venture_master_frame_with_main_sector_with_5M_and15M_inestment[df_country == \"USA\"]\n",
    "D2 =  venture_master_frame_with_main_sector_with_5M_and15M_inestment[df_country == \"GBR\"]\n",
    "D3 =  venture_master_frame_with_main_sector_with_5M_and15M_inestment[df_country == \"IND\"]\n",
    "\n",
    "\n",
    "\n",
    "#####################################\n",
    "#The total number (or count) of investments for each main sector in a separate column\n",
    "#\n",
    "#The total amount invested in each main sector in a separate column\n",
    "##################################\n",
    "\n",
    "\n",
    "D1_total_count_invested_per_sector = pd.DataFrame({'count' : D1.groupby( \"main_sector\" ).raised_amount_usd.size()}).reset_index()\n",
    "D1_total_amount_invested_per_sector = pd.DataFrame({'Sum' : D1.groupby( \"main_sector\" ).raised_amount_usd.sum()}).reset_index()\n",
    "D1['total_count_invested_per_sector'] = D1['main_sector'].map(D1_total_count_invested_per_sector.set_index('main_sector')['count'])\n",
    "D1['total_amount_invested_per_sector'] = D1['main_sector'].map(D1_total_amount_invested_per_sector.set_index('main_sector')['Sum'])\n",
    "\n",
    "D2_total_count_invested_per_sector = pd.DataFrame({'count' : D2.groupby( \"main_sector\" ).raised_amount_usd.size()}).reset_index()\n",
    "D2_total_amount_invested_per_sector = pd.DataFrame({'Sum' : D2.groupby( \"main_sector\" ).raised_amount_usd.sum()}).reset_index()\n",
    "D2['total_count_invested_per_sector'] = D2['main_sector'].map(D2_total_count_invested_per_sector.set_index('main_sector')['count'])\n",
    "D2['total_amount_invested_per_sector'] = D2['main_sector'].map(D2_total_amount_invested_per_sector.set_index('main_sector')['Sum'])\n",
    "\n",
    "D3_total_count_invested_per_sector = pd.DataFrame({'count' : D3.groupby( \"main_sector\" ).raised_amount_usd.size()}).reset_index()\n",
    "D3_total_amount_invested_per_sector = pd.DataFrame({'Sum' : D3.groupby( \"main_sector\" ).raised_amount_usd.sum()}).reset_index()\n",
    "D3['total_count_invested_per_sector'] = D3['main_sector'].map(D3_total_count_invested_per_sector.set_index('main_sector')['count'])\n",
    "D3['total_amount_invested_per_sector'] = D3['main_sector'].map(D3_total_amount_invested_per_sector.set_index('main_sector')['Sum'])\n",
    "\n",
    "######################## Table 5.1 #########################\n",
    "print(\"\\n############ Country-1 #############\\n\")\n",
    "print(\"Total number of investments %s \" %(D1.shape[0]))\n",
    "print(\"Total amount of investment %s\" %(D1.raised_amount_usd.sum())) \n",
    "\n",
    "all_sector_value_count = D1['main_sector'].value_counts()\n",
    "top_Sector = all_sector_value_count.index[0]\n",
    "second_best_Sector = all_sector_value_count.index[1]\n",
    "third_best_Sector = all_sector_value_count.index[2]\n",
    "\n",
    "\n",
    "print(\"Top sector (based on count of investments) %s\" %(top_Sector))\n",
    "print(\"Second best sector (based on count of investments) %s\" %(second_best_Sector))\n",
    "print(\"Third best sector (based on count of investments) %s\" %(all_sector_value_count.index[2]))\n",
    "print(\"Number of investments in the top sector : %s \" %(all_sector_value_count.iloc[0]))\n",
    "print(\"Number of investments in the second best sector : %s \" %(all_sector_value_count.iloc[1]))\n",
    "print(\"Number of investments in the third best sector : %s \" %(all_sector_value_count.iloc[2]))\n",
    "print(\"For top sector,company received the highest investment :%s\" %(D1[D1[\"main_sector\"] == top_Sector].groupby(\"name\")[\"raised_amount_usd\"].sum().idxmax()))\n",
    "print(\"For 2nd best sector,company received the highest investment :%s\" %(D1[D1[\"main_sector\"] == second_best_Sector].groupby(\"name\")[\"raised_amount_usd\"].sum().idxmax()))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n############ Country-2 #############\\n\")\n",
    "print(\"Total number of investments %s \" %(D2.shape[0]))\n",
    "print(\"Total amount of investment %s\" %(D2.raised_amount_usd.sum())) \n",
    "\n",
    "D2_all_sector_value_count = D2['main_sector'].value_counts()\n",
    "D2_top_Sector = D2_all_sector_value_count.index[0]\n",
    "D2_second_best_Sector = D2_all_sector_value_count.index[1]\n",
    "D2_third_best_Sector = D2_all_sector_value_count.index[2]\n",
    "\n",
    "\n",
    "print(\"Top sector (based on count of investments) %s\" %(D2_top_Sector))\n",
    "print(\"Second best sector (based on count of investments) %s\" %(D2_second_best_Sector))\n",
    "print(\"Third best sector (based on count of investments) %s\" %(D2_all_sector_value_count.index[2]))\n",
    "print(\"Number of investments in the top sector : %s \" %(D2_all_sector_value_count.iloc[0]))\n",
    "print(\"Number of investments in the second best sector : %s \" %(D2_all_sector_value_count.iloc[1]))\n",
    "print(\"Number of investments in the third best sector : %s \" %(D2_all_sector_value_count.iloc[2]))\n",
    "print(\"For top sector,company received the highest investment :%s\" %(D2[D2[\"main_sector\"] == D2_top_Sector].groupby(\"name\")[\"raised_amount_usd\"].sum().idxmax()))\n",
    "print(\"For 2nd best sector,company received the highest investment :%s\" %(D2[D2[\"main_sector\"] == D2_second_best_Sector].groupby(\"name\")[\"raised_amount_usd\"].sum().idxmax()))\n",
    "\n",
    "\n",
    "print(\"\\n############ Country-3 #############\\n\")\n",
    "print(\"Total number of investments %s \" %(D3.shape[0]))\n",
    "print(\"Total amount of investment %s\" %(D3.raised_amount_usd.sum())) \n",
    "\n",
    "D3_all_sector_value_count = D3['main_sector'].value_counts()\n",
    "D3_top_Sector = D3_all_sector_value_count.index[0]\n",
    "D3_second_best_Sector = D3_all_sector_value_count.index[1]\n",
    "D3_third_best_Sector = D3_all_sector_value_count.index[2]\n",
    "\n",
    "\n",
    "print(\"Top sector (based on count of investments) %s\" %(D3_top_Sector))\n",
    "print(\"Second best sector (based on count of investments) %s\" %(D3_second_best_Sector))\n",
    "print(\"Third best sector (based on count of investments) %s\" %(D3_all_sector_value_count.index[2]))\n",
    "print(\"Number of investments in the top sector : %s \" %(D3_all_sector_value_count.iloc[0]))\n",
    "print(\"Number of investments in the second best sector : %s \" %(D3_all_sector_value_count.iloc[1]))\n",
    "print(\"Number of investments in the third best sector : %s \" %(D3_all_sector_value_count.iloc[2]))\n",
    "print(\"For top sector,company received the highest investment :%s\" %(D3[D3[\"main_sector\"] == D3_top_Sector].groupby(\"name\")[\"raised_amount_usd\"].sum().idxmax()))\n",
    "print(\"For 2nd best sector,company received the highest investment :%s\" %(D3[D3[\"main_sector\"] == D3_second_best_Sector].groupby(\"name\")[\"raised_amount_usd\"].sum().idxmax()))\n",
    " \n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\" \n",
    "Plotting\n",
    "\"\"\"\n",
    "sns.set()\n",
    "    \n",
    "\n",
    "formatter = FuncFormatter(billions)\n",
    "fig, ax = plt.subplots(figsize=(8,10))\n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "br = top_9_countries.plot.bar(rot=0, alpha=1, color='lightblue')\n",
    "ax.get_children()[0].set_color('darkblue') \n",
    "ax.get_children()[2].set_color('darkblue') \n",
    "ax.get_children()[2].set_alpha(0.8)\n",
    "ax.get_children()[3].set_color('darkblue') \n",
    "ax.get_children()[3].set_alpha(0.7)\n",
    "ax.set_ylabel('Total investments in Billion dollor')\n",
    "ax.set_xlabel('Top 9 Countries')\n",
    "\n",
    "for index,data in enumerate(top_9_countries):\n",
    "    plt.text(x=index , y =data+1 , s=f\"{ '$%1.1fB' % (data*1e-9)  }\" , fontdict=dict(fontsize=9))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#2nd Plot\n",
    "\"\"\"\n",
    "    \n",
    "raw_data = {'Country': ['USA', 'GBR', 'IND'],\n",
    "        'top_sector': [all_sector_value_count.iloc[0], D2_all_sector_value_count.iloc[0], D3_all_sector_value_count.iloc[0]],\n",
    "        'second_best_sector': [all_sector_value_count.iloc[1], D2_all_sector_value_count.iloc[1],D3_all_sector_value_count.iloc[1]],\n",
    "        'third_best_sector': [all_sector_value_count.iloc[2], D2_all_sector_value_count.iloc[2], D3_all_sector_value_count.iloc[2]]}\n",
    "df = pd.DataFrame(raw_data, columns = ['Country', 'top_sector', 'second_best_sector', 'third_best_sector'])\n",
    "\n",
    "\n",
    "\n",
    "# Setting the positions and width for the bars\n",
    "pos = list(range(len(df['top_sector']))) \n",
    "width = 0.1\n",
    "    \n",
    "# Plotting the bars\n",
    "fig, ax = plt.subplots(figsize=(8,10))\n",
    "\n",
    "# Create a bar for top sector data\n",
    "plt.bar(pos, df['top_sector'], width, alpha=1, color='green', label=df['Country'][0]) \n",
    "\n",
    "# Create a bar with second_best_sector data\n",
    "plt.bar([p + width for p in pos], df['second_best_sector'],width, alpha=1, color='red', label=df['Country'][1]) \n",
    "\n",
    "# Create a bar with third_best_sector data\n",
    "plt.bar([p + width*2 for p in pos], df['third_best_sector'], width, alpha=1, color='blue', label=df['Country'][2]) \n",
    "\n",
    "\n",
    "# Set the y axis label\n",
    "ax.set_ylabel('Number of investments')\n",
    "\n",
    "# Set the chart's title\n",
    "ax.set_title('A plot showing the number of investments in the top 3 sectors of the top 3 countries')\n",
    "\n",
    "tick_spacing = 50\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n",
    "\n",
    "# Set the position of the x ticks\n",
    "ax.set_xticks([p + 0.1 * width for p in pos])\n",
    "\n",
    "# Set the labels for the x ticks\n",
    "ax.set_xticklabels(df['Country'])\n",
    "\n",
    "# Setting the x-axis and y-axis limits\n",
    "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "\n",
    "# Adding the legend and showing the plot\n",
    "plt.legend(['top_sector', 'second_best_sector', 'third_best_sector'], loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "         \n",
    "             \n",
    "#---------------------- Third plot -------------------------\n",
    "#A plot showing the fraction of total investments (globally) in venture, seed, and private equity, \n",
    "#and the average amount of investment in each funding type. This chart should make it clear that a \n",
    "#certain funding type (FT) is best suited for Spark Funds.\n",
    "\n",
    "\n",
    "\n",
    "dd = master_frame[(df_funding == \"venture\") | (df_funding== \"seed\") | (df_funding == \"private_equity\")]\n",
    "\n",
    "series_total_investments = dd.groupby(\"funding_round_type\")[\"raised_amount_usd\"].sum()\n",
    "colors = ['cyan', 'yellow', 'lightgreen']\n",
    "sns.set()\n",
    "series_total_investments.plot(colors=colors, wedgeprops={'alpha':1}, textprops={'fontsize': 12}, explode=(0,0,0.08),kind='pie', startangle=90, shadow = True,  title='Fraction of total investments', figsize=[8,8],\n",
    "          autopct=lambda p: '{:.2f}%(${:.0f}B)'.format(p,(p/100)*series_total_investments.sum()*(1e-9)))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39717, 28)\n"
     ]
    },
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-227-38f1b35ba6e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[0mst3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"st3.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \"\"\" \n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "import warnings\n",
    "import bamboolib\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def interest_rate(s):\n",
    "    s = str(s)\n",
    "    return float(s.split(\"%\")[0])\n",
    "\n",
    "\n",
    "df = pd.read_csv(r\"loan.csv\")\n",
    "#df.to_csv('tmp.csv')\n",
    "for i in df.columns:\n",
    "    if( int(100 * df[i].isnull().sum()/df.shape[0])>10):\n",
    "        df = df.drop(columns=i)\n",
    "\n",
    "df = df.drop(columns = [\"title\",\"member_id\",\"funded_amnt\",\"emp_length\",\"emp_title\",\"issue_d\",\"last_credit_pull_d\",\"tax_liens\",\"pub_rec_bankruptcies\",\"chargeoff_within_12_mths\",\"collections_12_mths_ex_med\", \"sub_grade\", \"grade\",\"out_prncp\", \"out_prncp_inv\" ,\"collection_recovery_fee\", \"recoveries\",\"zip_code\", \"url\",\"initial_list_status\",\"pymnt_plan\",\"policy_code\", \"application_type\",\"acc_now_delinq\", \"delinq_amnt\"], axis=1)\n",
    "\n",
    "#df.annual_inc.plot(kind=\"bar\")\n",
    "#df.plot.box(x='id', y='annual_inc', c='blue')\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "\n",
    "#output:\n",
    "#--------\n",
    "#Low-Risk, Mid-Risk, High-Risk\n",
    "\n",
    "\n",
    "#1. Higher loan terms\n",
    "#2. More dti ==> more chances of defaulter\n",
    "#3. Region base \n",
    "\n",
    "#df.groupby('loan_status').term.count()\n",
    "df.int_rate = df[\"int_rate\"].apply(interest_rate)\n",
    "df.groupby('loan_status').int_rate.count()\n",
    "\n",
    "\"\"\" \n",
    "st = pd.DataFrame([\"Northeast\", \"Midwest\",\"South\",\"WEST\"], [\"ME\", \"NH\", \"VT\",\"MA\",\"RI\",\"CT\",\"NY\",\"PA\",\"NJ\"],\n",
    "                  [\"WI\",\"MI\",\"IL\",\"IN\",\"OH\",\"ND\",\"SD\",\"NE\",\"KA\",\"MN\",\"LO\",\"MO\"],\n",
    "                 [\"DE\",\"MD\",\"DC\",\"VA\",\"WV\",\"NC\", \"SC\", \"GA\",\"FL\",\"KY\", \"TN\", \"MS\", \"AL\", \"OK\", \"TX\", \"AR\", \"LA\"],\n",
    "                 [\"ID\",\"MT\",\"WY\", \"NV\", \"UT\", \"CO\", \"AZ\", \"NM\", \"AK\", \"WA\", \"OR\", \"CA\", \"HI\"])\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "st2 = pd.read_csv(r\"st2.csv\")\n",
    "st2 = st2.loc[:, ~st2.columns.str.contains('^Unnamed')]\n",
    "st2 = st2.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "st3 = pd.read_csv(r\"st3.csv\")\n",
    "\n",
    "\"\"\" \n",
    "dd = pd.merge(st2, st3,  on='State', how=\"outer\")\n",
    "dd = dd.dropna()\n",
    "print(dd.groupby(\"Region\")[\"Charged Off\"].sum())\n",
    "t1 = dd.groupby(\"Region\").sum()\n",
    "t1['total'] = t1[\"Charged Off\"] + t1[\"Fully Paid\"]\n",
    "t1[\"co_per\"] = 100 * (t1[\"Charged Off\"] / t1['total'])\n",
    "t1[\"fp_per\"] = 100 * (t1[\"Fully Paid\"] / t1['total'])\n",
    "t1\n",
    "\"\"\"\n",
    "s1 = df.groupby([\"addr_state\", \"loan_status\"]).size()\n",
    "\n",
    "d1 = pd.DataFrame(s1).reset_index()\n",
    "#print(d1)\n",
    "\n",
    "d1.columns = ['State', 'loan_status', 'val']\n",
    "#d1 = pd.DataFrame(pd.DataFrame({ k : d1.loc[d1['loan_status'] == k, 'val'].values for k in d1['loan_status'].unique() }), columns=d1['loan_status'].unique())\n",
    "d2 = (d1.set_index(['loan_status', d1.groupby('loan_status').cumcount()])['val']\n",
    "   .unstack(0).rename_axis([None], axis=1))\n",
    "\n",
    "print(d2)\n",
    "\n",
    "d2['State'] = d1.State.unique()\n",
    "d2 = d2[['State', 'Charged Off','Fully Paid']]\n",
    "\n",
    "print(st2)\n",
    "\n",
    "print(df.shape)\n",
    "for i in df.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
